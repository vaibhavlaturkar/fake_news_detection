{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd741413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd8b208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verifiedby</th>\n",
       "      <th>country</th>\n",
       "      <th>class</th>\n",
       "      <th>title</th>\n",
       "      <th>published_date</th>\n",
       "      <th>country1</th>\n",
       "      <th>country2</th>\n",
       "      <th>country3</th>\n",
       "      <th>country4</th>\n",
       "      <th>article_source</th>\n",
       "      <th>...</th>\n",
       "      <th>binary_class</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>source_domain</th>\n",
       "      <th>domain_is_credible</th>\n",
       "      <th>domain_fake_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La Silla Vacía</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>The coronavirus is an amplified bacteria rela...</td>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>No Country</td>\n",
       "      <td>No Country</td>\n",
       "      <td>No Country</td>\n",
       "      <td>https://lasillavacia.com/detector-video-falso-...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.506427</td>\n",
       "      <td>https://lasillavacia.com/</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Newtral.es</td>\n",
       "      <td>Spain</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>A law allows people to go for a run during th...</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>Spain</td>\n",
       "      <td>No Country</td>\n",
       "      <td>No Country</td>\n",
       "      <td>No Country</td>\n",
       "      <td>https://www.newtral.es/la-broma-de-que-a-los-r...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.621253</td>\n",
       "      <td>https://www.newtral.es/</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FactCrescendo</td>\n",
       "      <td>India</td>\n",
       "      <td>False</td>\n",
       "      <td>Chinese converting to Islam after realizing t...</td>\n",
       "      <td>2020-02-20</td>\n",
       "      <td>India</td>\n",
       "      <td>No Country</td>\n",
       "      <td>No Country</td>\n",
       "      <td>No Country</td>\n",
       "      <td>https://english.factcrescendo.com/2020/02/20/c...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544073</td>\n",
       "      <td>https://english.factcrescendo.com/</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>France 24 Observers</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "      <td>Bat market and bat meat are being sold in Wuhan.</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>France</td>\n",
       "      <td>No Country</td>\n",
       "      <td>No Country</td>\n",
       "      <td>No Country</td>\n",
       "      <td>https://observers.france24.com/fr/20200130-int...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>https://observers.france24.com/</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agência Lupa</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>False</td>\n",
       "      <td>You can self-diagnose COVID-19 by holding you...</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>No Country</td>\n",
       "      <td>No Country</td>\n",
       "      <td>No Country</td>\n",
       "      <td>https://piaui.folha.uol.com.br/lupa/2020/03/16...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.541507</td>\n",
       "      <td>https://piaui.folha.uol.com.br/</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             verifiedby    country  class   \n",
       "0        La Silla Vacía   Colombia  FALSE  \\\n",
       "1            Newtral.es      Spain  FALSE   \n",
       "2         FactCrescendo      India  False   \n",
       "3   France 24 Observers     France  False   \n",
       "4          Agência Lupa     Brazil  False   \n",
       "\n",
       "                                               title published_date   \n",
       "0   The coronavirus is an amplified bacteria rela...     2020-06-17  \\\n",
       "1   A law allows people to go for a run during th...     2020-04-09   \n",
       "2   Chinese converting to Islam after realizing t...     2020-02-20   \n",
       "3   Bat market and bat meat are being sold in Wuhan.     2020-01-27   \n",
       "4   You can self-diagnose COVID-19 by holding you...     2020-03-16   \n",
       "\n",
       "    country1    country2    country3    country4   \n",
       "0   Colombia  No Country  No Country  No Country  \\\n",
       "1      Spain  No Country  No Country  No Country   \n",
       "2      India  No Country  No Country  No Country   \n",
       "3     France  No Country  No Country  No Country   \n",
       "4     Brazil  No Country  No Country  No Country   \n",
       "\n",
       "                                      article_source  ... binary_class   \n",
       "0  https://lasillavacia.com/detector-video-falso-...  ...        False  \\\n",
       "1  https://www.newtral.es/la-broma-de-que-a-los-r...  ...        False   \n",
       "2  https://english.factcrescendo.com/2020/02/20/c...  ...        False   \n",
       "3  https://observers.france24.com/fr/20200130-int...  ...        False   \n",
       "4  https://piaui.folha.uol.com.br/lupa/2020/03/16...  ...        False   \n",
       "\n",
       "     year month title_length  title_polarity  title_subjectivity   \n",
       "0  2020.0   6.0            9             0.0            0.400000  \\\n",
       "1  2020.0   4.0           16             0.0            0.000000   \n",
       "2  2020.0   2.0           16             0.0            0.000000   \n",
       "3  2020.0   1.0           10             0.0            0.000000   \n",
       "4  2020.0   3.0           24             0.0            0.333333   \n",
       "\n",
       "   lexical_diversity                       source_domain  domain_is_credible   \n",
       "0           0.506427           https://lasillavacia.com/                True  \\\n",
       "1           0.621253             https://www.newtral.es/                True   \n",
       "2           0.544073  https://english.factcrescendo.com/                True   \n",
       "3           0.633663     https://observers.france24.com/                True   \n",
       "4           0.541507     https://piaui.folha.uol.com.br/                True   \n",
       "\n",
       "   domain_fake_ratio  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset to understand its structure and first few entries\n",
    "file_path = '../data/clean_data.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4508bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features (X) and target (y)\n",
    "X = data.drop(['binary_class','class','published_date','article_source','ref_source','year'], axis=1)\n",
    "y = data['binary_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e2cf427",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['title','source_title','content_text']\n",
    "cat_features = ['verifiedby','country','country1','country2','country3','country4','lang','source_domain','domain_is_credible']\n",
    "num_features = ['month','title_length','title_polarity','title_subjectivity','lexical_diversity','domain_fake_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e50ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding for categorical variables\n",
    "# label_encoders = {}\n",
    "# for column in cat_features:\n",
    "#     label_encoders[column] = LabelEncoder()\n",
    "#     X[column] = label_encoders[column].fit_transform(X[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ee572c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verifiedby</th>\n",
       "      <th>country</th>\n",
       "      <th>title</th>\n",
       "      <th>country1</th>\n",
       "      <th>country2</th>\n",
       "      <th>country3</th>\n",
       "      <th>country4</th>\n",
       "      <th>source_title</th>\n",
       "      <th>content_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>month</th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>source_domain</th>\n",
       "      <th>domain_is_credible</th>\n",
       "      <th>domain_fake_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>51</td>\n",
       "      <td>The coronavirus is an amplified bacteria rela...</td>\n",
       "      <td>14</td>\n",
       "      <td>87</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>Detector a video falso que dice que el Covid e...</td>\n",
       "      <td>La Silla Vacía usa Cookies para mejorar la exp...</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.506427</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>244</td>\n",
       "      <td>A law allows people to go for a run during th...</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>La broma de que a los “runners” se les permite...</td>\n",
       "      <td>En los últimos días nos ha llegado una consult...</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.621253</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>118</td>\n",
       "      <td>Chinese converting to Islam after realizing t...</td>\n",
       "      <td>36</td>\n",
       "      <td>87</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>Are Chinese people converting to Islam in fear...</td>\n",
       "      <td>The fact behind every news!, Ever since the Wo...</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544073</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>78</td>\n",
       "      <td>Bat market and bat meat are being sold in Wuhan.</td>\n",
       "      <td>27</td>\n",
       "      <td>87</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>La soupe à la chauve-souris, un plat prisé en ...</td>\n",
       "      <td>عربي, English, Français, Contribuer, فارسی, عر...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>You can self-diagnose COVID-19 by holding you...</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>#Verificamos: É falso que quem consegue prende...</td>\n",
       "      <td>, “O novo CORONA VÍRUS pode não mostrar sinais...</td>\n",
       "      <td>20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.541507</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>A video has been viewed thousands of times on...</td>\n",
       "      <td>51</td>\n",
       "      <td>87</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>This video shows a safety drill at the Malaysi...</td>\n",
       "      <td>Below is a screenshot of the misleading post:,...</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.584786</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>14</td>\n",
       "      <td>216</td>\n",
       "      <td>An audio shared on WhatsApp indicates that th...</td>\n",
       "      <td>64</td>\n",
       "      <td>87</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>Coronavirus: Desinformación y mitos | Convoca</td>\n",
       "      <td>Menú, Buscar, Los peruanos nos quedamos en cas...</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>While the world was worried with COVID-19, Ch...</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>#Verificamos: É falsa informação de que a Chin...</td>\n",
       "      <td>, “Enquanto o mundo está de quarentena, a Chin...</td>\n",
       "      <td>20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.660465</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>48</td>\n",
       "      <td>320</td>\n",
       "      <td>Doctors encouraged by hospitals and AMA to ov...</td>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>Fact Check: Doctors Are NOT 'Encouraged' By Ho...</td>\n",
       "      <td>The claims suggesting hospitals are overreport...</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>64</td>\n",
       "      <td>217</td>\n",
       "      <td>Inhaling the steam from boiled water with dis...</td>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>FALSE: Salt water steam can cure coronavirus</td>\n",
       "      <td>Read more, Inhaling salt water steam is not an...</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.562670</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5834 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      verifiedby  country                                              title   \n",
       "0             46       51   The coronavirus is an amplified bacteria rela...  \\\n",
       "1             55      244   A law allows people to go for a run during th...   \n",
       "2             33      118   Chinese converting to Islam after realizing t...   \n",
       "3             40       78   Bat market and bat meat are being sold in Wuhan.   \n",
       "4              5       40   You can self-diagnose COVID-19 by holding you...   \n",
       "...          ...      ...                                                ...   \n",
       "5829           2      172   A video has been viewed thousands of times on...   \n",
       "5830          14      216   An audio shared on WhatsApp indicates that th...   \n",
       "5831           5       40   While the world was worried with COVID-19, Ch...   \n",
       "5832          48      320   Doctors encouraged by hospitals and AMA to ov...   \n",
       "5833          64      217   Inhaling the steam from boiled water with dis...   \n",
       "\n",
       "      country1  country2  country3  country4   \n",
       "0           14        87        45        20  \\\n",
       "1           78        87        45        20   \n",
       "2           36        87        45        20   \n",
       "3           27        87        45        20   \n",
       "4            8        87        45        20   \n",
       "...        ...       ...       ...       ...   \n",
       "5829        51        87        45        20   \n",
       "5830        64        87        45        20   \n",
       "5831         8        87        45        20   \n",
       "5832        90        87        45        20   \n",
       "5833        65        87        45        20   \n",
       "\n",
       "                                           source_title   \n",
       "0     Detector a video falso que dice que el Covid e...  \\\n",
       "1     La broma de que a los “runners” se les permite...   \n",
       "2     Are Chinese people converting to Islam in fear...   \n",
       "3     La soupe à la chauve-souris, un plat prisé en ...   \n",
       "4     #Verificamos: É falso que quem consegue prende...   \n",
       "...                                                 ...   \n",
       "5829  This video shows a safety drill at the Malaysi...   \n",
       "5830      Coronavirus: Desinformación y mitos | Convoca   \n",
       "5831  #Verificamos: É falsa informação de que a Chin...   \n",
       "5832  Fact Check: Doctors Are NOT 'Encouraged' By Ho...   \n",
       "5833       FALSE: Salt water steam can cure coronavirus   \n",
       "\n",
       "                                           content_text  lang  month   \n",
       "0     La Silla Vacía usa Cookies para mejorar la exp...     6    6.0  \\\n",
       "1     En los últimos días nos ha llegado una consult...     6    4.0   \n",
       "2     The fact behind every news!, Ever since the Wo...     5    2.0   \n",
       "3     عربي, English, Français, Contribuer, فارسی, عر...     9    1.0   \n",
       "4     , “O novo CORONA VÍRUS pode não mostrar sinais...    20    3.0   \n",
       "...                                                 ...   ...    ...   \n",
       "5829  Below is a screenshot of the misleading post:,...     5    4.0   \n",
       "5830  Menú, Buscar, Los peruanos nos quedamos en cas...     6    3.0   \n",
       "5831  , “Enquanto o mundo está de quarentena, a Chin...    20    6.0   \n",
       "5832  The claims suggesting hospitals are overreport...     5    4.0   \n",
       "5833  Read more, Inhaling salt water steam is not an...     5    3.0   \n",
       "\n",
       "      title_length  title_polarity  title_subjectivity  lexical_diversity   \n",
       "0                9            0.00            0.400000           0.506427  \\\n",
       "1               16            0.00            0.000000           0.621253   \n",
       "2               16            0.00            0.000000           0.544073   \n",
       "3               10            0.00            0.000000           0.633663   \n",
       "4               24            0.00            0.333333           0.541507   \n",
       "...            ...             ...                 ...                ...   \n",
       "5829            44           -0.10            0.100000           0.584786   \n",
       "5830            16            0.00            0.100000           0.715328   \n",
       "5831            22            0.25            0.312500           0.660465   \n",
       "5832            10            0.00            0.000000           0.500000   \n",
       "5833            22            0.60            0.800000           0.562670   \n",
       "\n",
       "      source_domain  domain_is_credible  domain_fake_ratio  \n",
       "0                56                   1                0.0  \n",
       "1               105                   1                0.0  \n",
       "2                32                   1                0.0  \n",
       "3                64                   1                0.0  \n",
       "4                70                   1                0.0  \n",
       "...             ...                 ...                ...  \n",
       "5829             35                   1                0.0  \n",
       "5830             23                   1                0.0  \n",
       "5831             70                   1                0.0  \n",
       "5832             57                   1                0.0  \n",
       "5833            109                   1                0.0  \n",
       "\n",
       "[5834 rows x 18 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4711c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)  # For reproducibility\n",
    "embedded_features = {}\n",
    "for column in cat_features:\n",
    "    # For each unique category, we create a random 5-dimensional embedding\n",
    "    unique_values = X[column].unique()\n",
    "    embedding_size = 5  # As per the instruction\n",
    "    embeddings = np.random.rand(len(unique_values), embedding_size)\n",
    "    embedded_features[column] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "020ff214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb284653bcf34459a51a0ec4610ed9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5cdf0c35cb4647b1de856989b44788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbf80fdfcd74060bb7cccccaca93b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a14b699bf948e284bcdee0dc40fd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ce3217221b4e55ad297f3c18b4a7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'pooler.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Load the tokenizer and model from the BERT pre-trained 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = BertModel.from_pretrained('distilbert-base-uncased')\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5fa4bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode sequences in the list of text_features\n",
    "def encode_text_features(texts, max_length):\n",
    "    # Tokenize all texts and map the tokens to their word IDs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for text in texts:\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    \n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5bc281cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def get_bert_embeddings(model, texts, max_length=128, batch_size=16):\n",
    "    # Prepare the progress bar\n",
    "    progress_bar = tqdm(range(0, len(texts), batch_size), desc='Encoding', leave=True)\n",
    "\n",
    "    # Batch the data to avoid running out of memory on GPU\n",
    "    cls_embeddings = []\n",
    "    for start_idx in progress_bar:\n",
    "        # Encode batch of texts\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_texts = texts[start_idx:end_idx]\n",
    "        input_ids, attention_masks = encode_text_features(batch_texts, max_length)\n",
    "        \n",
    "        # Get embeddings from BERT\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_masks)\n",
    "            last_hidden_states = outputs.last_hidden_state\n",
    "        \n",
    "        # Use the [CLS] token embeddings\n",
    "        cls_embeddings_batch = last_hidden_states[:, 0, :].cpu().numpy()\n",
    "        cls_embeddings.append(cls_embeddings_batch)\n",
    "\n",
    "    # Concatenate all batch embeddings\n",
    "    cls_embeddings = np.concatenate(cls_embeddings, axis=0)\n",
    "\n",
    "    return cls_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5430d8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|███████████████████████████████| 365/365 [05:58<00:00,  1.02it/s]\n",
      "Encoding: 100%|███████████████████████████████| 365/365 [05:59<00:00,  1.01it/s]\n",
      "Encoding: 100%|███████████████████████████████| 365/365 [07:12<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# For each categorical feature, create an array where each row corresponds to the embedding of that feature for each sample\n",
    "cat_embeddings = np.concatenate([embedded_features[column][X[column].values].reshape(-1, 5) for column in cat_features], axis=1)\n",
    "\n",
    "# For each text feature, create an array where each row corresponds to the embedding of that feature for each sample\n",
    "text_embeddings = {}\n",
    "for feature in text_features:\n",
    "    text_embeddings[feature] = get_bert_embeddings(model=model, texts=X[feature].tolist())\n",
    "\n",
    "text_embeddings_concatenated = np.concatenate([text_embeddings[feature] for feature in text_features], axis=1)\n",
    "\n",
    "# Concatenate the numerical features, categorical embeddings, and text embeddings\n",
    "final_feature_data = np.hstack((num_feature_data, cat_embeddings, text_embeddings_concatenated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5fc79ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5834, 6)\n"
     ]
    }
   ],
   "source": [
    "print(num_feature_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Assuming num_features_end represents the number of numerical features\n",
    "num_features_end = 6\n",
    "\n",
    "# Create an imputer object with a mean filling strategy for numerical features\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "X_num = num_imputer.fit_transform(final_feature_data[:, :num_features_end])  # assuming num_features_end is the index where numerical features end\n",
    "\n",
    "# Create an imputer object with a constant filling strategy for categorical features\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_cat = cat_imputer.fit_transform(final_feature_data[:, num_features_end:])\n",
    "\n",
    "# Concatenate the imputed features back together\n",
    "final_feature_data_ = np.concatenate((X_num, X_cat), axis=1)\n",
    "\n",
    "# Check if there are any NaN values left\n",
    "print(\"NaNs in X_train:\", np.isnan(final_feature_data_).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf49ec4",
   "metadata": {},
   "source": [
    "#### Resampling Techniques: SMOTE for Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4a248360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Directly convert the 'y' feature from boolean to binary 1/0\n",
    "y_binary = y.astype(int)\n",
    "\n",
    "#Oversample the minority class using SMOTE\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(final_feature_data_, y_binary)\n",
    "\n",
    "# Now X_resampled and y_resampled can be used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0fc47d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9230, 2355), (9230,), (2308, 2355), (2308,))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42,stratify=y_resampled)\n",
    "\n",
    "# Check the shape of the prepared feature data and target variable\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "014b3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def focal_loss(gamma=2., alpha=4.):\n",
    "#     gamma = float(gamma)\n",
    "#     alpha = float(alpha)\n",
    "#     def focal_loss_fixed(y_true, y_pred):\n",
    "#         \"\"\"Focal loss for binary classification with imbalanced dataset\"\"\"\n",
    "#         epsilon = 1.e-9\n",
    "#         y_true = tf.cast(y_true, tf.float32)\n",
    "#         y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "#         pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "#         pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "#         return -tf.reduce_sum(alpha * tf.pow(1. - pt_1, gamma) * tf.math.log(pt_1)) \\\n",
    "#                -tf.reduce_sum((1 - alpha) * tf.pow(pt_0, gamma) * tf.math.log(1. - pt_0))\n",
    "#     return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "aa4aeeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 256)               603136    \n",
      "                                                                 \n",
      " batch_normalization_30 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_31 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 637697 (2.43 MB)\n",
      "Trainable params: 636929 (2.43 MB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Assuming final_feature_data.shape[1] is the number of features from the concatenated feature set\n",
    "input_shape = final_feature_data.shape[1]\n",
    "\n",
    "# Input layer\n",
    "model.add(Dense(256, input_shape=(input_shape,), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid activation for binary classification\n",
    "\n",
    "# Lower the learning rate\n",
    "optimizer = Adam(learning_rate=1e-5)\n",
    "\n",
    "# Compile the model with the new optimizer\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
    "#model.compile(optimizer=optimizer, loss=focal_loss(alpha=1), metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d668f688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "361/361 [==============================] - 2s 3ms/step - loss: 0.6902 - accuracy: 0.6742 - precision: 0.6651 - recall: 0.7017 - val_loss: 0.4045 - val_accuracy: 0.8315 - val_precision: 0.7552 - val_recall: 0.9809\n",
      "Epoch 2/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.4477 - accuracy: 0.8036 - precision: 0.7845 - recall: 0.8372 - val_loss: 0.2511 - val_accuracy: 0.9047 - val_precision: 0.8454 - val_recall: 0.9905\n",
      "Epoch 3/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.3547 - accuracy: 0.8547 - precision: 0.8302 - recall: 0.8917 - val_loss: 0.1982 - val_accuracy: 0.9311 - val_precision: 0.8801 - val_recall: 0.9983\n",
      "Epoch 4/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.3002 - accuracy: 0.8774 - precision: 0.8539 - recall: 0.9107 - val_loss: 0.1475 - val_accuracy: 0.9562 - val_precision: 0.9195 - val_recall: 1.0000\n",
      "Epoch 5/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.2587 - accuracy: 0.8960 - precision: 0.8746 - recall: 0.9246 - val_loss: 0.1151 - val_accuracy: 0.9636 - val_precision: 0.9321 - val_recall: 1.0000\n",
      "Epoch 6/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.2239 - accuracy: 0.9158 - precision: 0.8889 - recall: 0.9504 - val_loss: 0.1437 - val_accuracy: 0.9523 - val_precision: 0.9130 - val_recall: 1.0000\n",
      "Epoch 7/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.1930 - accuracy: 0.9283 - precision: 0.9048 - recall: 0.9574 - val_loss: 0.1176 - val_accuracy: 0.9597 - val_precision: 0.9254 - val_recall: 1.0000\n",
      "Epoch 8/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.1792 - accuracy: 0.9366 - precision: 0.9144 - recall: 0.9634 - val_loss: 0.1075 - val_accuracy: 0.9614 - val_precision: 0.9284 - val_recall: 1.0000\n",
      "Epoch 9/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.1615 - accuracy: 0.9450 - precision: 0.9204 - recall: 0.9742 - val_loss: 0.0892 - val_accuracy: 0.9675 - val_precision: 0.9390 - val_recall: 1.0000\n",
      "Epoch 10/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.1485 - accuracy: 0.9502 - precision: 0.9257 - recall: 0.9789 - val_loss: 0.0964 - val_accuracy: 0.9627 - val_precision: 0.9306 - val_recall: 1.0000\n",
      "Epoch 11/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.1374 - accuracy: 0.9516 - precision: 0.9273 - recall: 0.9799 - val_loss: 0.0758 - val_accuracy: 0.9744 - val_precision: 0.9514 - val_recall: 1.0000\n",
      "Epoch 12/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.1271 - accuracy: 0.9585 - precision: 0.9400 - recall: 0.9795 - val_loss: 0.0688 - val_accuracy: 0.9753 - val_precision: 0.9529 - val_recall: 1.0000\n",
      "Epoch 13/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.1186 - accuracy: 0.9617 - precision: 0.9431 - recall: 0.9827 - val_loss: 0.0833 - val_accuracy: 0.9684 - val_precision: 0.9405 - val_recall: 1.0000\n",
      "Epoch 14/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.1112 - accuracy: 0.9657 - precision: 0.9481 - recall: 0.9853 - val_loss: 0.0488 - val_accuracy: 0.9844 - val_precision: 0.9697 - val_recall: 1.0000\n",
      "Epoch 15/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9679 - precision: 0.9500 - recall: 0.9879 - val_loss: 0.0566 - val_accuracy: 0.9805 - val_precision: 0.9625 - val_recall: 1.0000\n",
      "Epoch 16/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0985 - accuracy: 0.9680 - precision: 0.9499 - recall: 0.9882 - val_loss: 0.0658 - val_accuracy: 0.9770 - val_precision: 0.9561 - val_recall: 1.0000\n",
      "Epoch 17/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0873 - accuracy: 0.9718 - precision: 0.9550 - recall: 0.9903 - val_loss: 0.0470 - val_accuracy: 0.9835 - val_precision: 0.9681 - val_recall: 1.0000\n",
      "Epoch 18/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0915 - accuracy: 0.9711 - precision: 0.9544 - recall: 0.9894 - val_loss: 0.0453 - val_accuracy: 0.9840 - val_precision: 0.9689 - val_recall: 1.0000\n",
      "Epoch 19/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0808 - accuracy: 0.9736 - precision: 0.9585 - recall: 0.9899 - val_loss: 0.0408 - val_accuracy: 0.9857 - val_precision: 0.9722 - val_recall: 1.0000\n",
      "Epoch 20/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0727 - accuracy: 0.9772 - precision: 0.9624 - recall: 0.9932 - val_loss: 0.0301 - val_accuracy: 0.9913 - val_precision: 0.9830 - val_recall: 1.0000\n",
      "Epoch 21/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0768 - accuracy: 0.9765 - precision: 0.9642 - recall: 0.9898 - val_loss: 0.0268 - val_accuracy: 0.9935 - val_precision: 0.9872 - val_recall: 1.0000\n",
      "Epoch 22/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0725 - accuracy: 0.9765 - precision: 0.9630 - recall: 0.9912 - val_loss: 0.0299 - val_accuracy: 0.9892 - val_precision: 0.9788 - val_recall: 1.0000\n",
      "Epoch 23/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0661 - accuracy: 0.9802 - precision: 0.9684 - recall: 0.9929 - val_loss: 0.0245 - val_accuracy: 0.9922 - val_precision: 0.9846 - val_recall: 1.0000\n",
      "Epoch 24/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0656 - accuracy: 0.9801 - precision: 0.9681 - recall: 0.9929 - val_loss: 0.0216 - val_accuracy: 0.9944 - val_precision: 0.9889 - val_recall: 1.0000\n",
      "Epoch 25/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0607 - accuracy: 0.9819 - precision: 0.9705 - recall: 0.9939 - val_loss: 0.0210 - val_accuracy: 0.9944 - val_precision: 0.9889 - val_recall: 1.0000\n",
      "Epoch 26/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0545 - accuracy: 0.9841 - precision: 0.9729 - recall: 0.9960 - val_loss: 0.0196 - val_accuracy: 0.9944 - val_precision: 0.9889 - val_recall: 1.0000\n",
      "Epoch 27/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0521 - accuracy: 0.9838 - precision: 0.9732 - recall: 0.9950 - val_loss: 0.0288 - val_accuracy: 0.9909 - val_precision: 0.9821 - val_recall: 1.0000\n",
      "Epoch 28/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0496 - accuracy: 0.9867 - precision: 0.9790 - recall: 0.9946 - val_loss: 0.0155 - val_accuracy: 0.9961 - val_precision: 0.9923 - val_recall: 1.0000\n",
      "Epoch 29/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0505 - accuracy: 0.9846 - precision: 0.9742 - recall: 0.9955 - val_loss: 0.0166 - val_accuracy: 0.9944 - val_precision: 0.9889 - val_recall: 1.0000\n",
      "Epoch 30/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0474 - accuracy: 0.9867 - precision: 0.9787 - recall: 0.9951 - val_loss: 0.0135 - val_accuracy: 0.9965 - val_precision: 0.9931 - val_recall: 1.0000\n",
      "Epoch 31/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0448 - accuracy: 0.9867 - precision: 0.9795 - recall: 0.9941 - val_loss: 0.0113 - val_accuracy: 0.9965 - val_precision: 0.9931 - val_recall: 1.0000\n",
      "Epoch 32/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0429 - accuracy: 0.9876 - precision: 0.9791 - recall: 0.9965 - val_loss: 0.0139 - val_accuracy: 0.9961 - val_precision: 0.9923 - val_recall: 1.0000\n",
      "Epoch 33/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0424 - accuracy: 0.9880 - precision: 0.9800 - recall: 0.9962 - val_loss: 0.0110 - val_accuracy: 0.9970 - val_precision: 0.9940 - val_recall: 1.0000\n",
      "Epoch 34/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9893 - precision: 0.9827 - recall: 0.9962 - val_loss: 0.0086 - val_accuracy: 0.9970 - val_precision: 0.9940 - val_recall: 1.0000\n",
      "Epoch 35/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9893 - precision: 0.9822 - recall: 0.9967 - val_loss: 0.0104 - val_accuracy: 0.9970 - val_precision: 0.9940 - val_recall: 1.0000\n",
      "Epoch 36/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0355 - accuracy: 0.9899 - precision: 0.9831 - recall: 0.9971 - val_loss: 0.0090 - val_accuracy: 0.9965 - val_precision: 0.9931 - val_recall: 1.0000\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0354 - accuracy: 0.9899 - precision: 0.9832 - recall: 0.9969 - val_loss: 0.0091 - val_accuracy: 0.9974 - val_precision: 0.9948 - val_recall: 1.0000\n",
      "Epoch 38/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.9910 - precision: 0.9846 - recall: 0.9976 - val_loss: 0.0080 - val_accuracy: 0.9983 - val_precision: 0.9965 - val_recall: 1.0000\n",
      "Epoch 39/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9916 - precision: 0.9856 - recall: 0.9977 - val_loss: 0.0093 - val_accuracy: 0.9974 - val_precision: 0.9948 - val_recall: 1.0000\n",
      "Epoch 40/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.9911 - precision: 0.9861 - recall: 0.9962 - val_loss: 0.0080 - val_accuracy: 0.9974 - val_precision: 0.9948 - val_recall: 1.0000\n",
      "Epoch 41/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9911 - precision: 0.9854 - recall: 0.9969 - val_loss: 0.0055 - val_accuracy: 0.9987 - val_precision: 0.9974 - val_recall: 1.0000\n",
      "Epoch 42/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9924 - precision: 0.9870 - recall: 0.9979 - val_loss: 0.0047 - val_accuracy: 0.9996 - val_precision: 0.9991 - val_recall: 1.0000\n",
      "Epoch 43/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0278 - accuracy: 0.9924 - precision: 0.9876 - recall: 0.9972 - val_loss: 0.0065 - val_accuracy: 0.9987 - val_precision: 0.9974 - val_recall: 1.0000\n",
      "Epoch 44/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.9909 - precision: 0.9864 - recall: 0.9955 - val_loss: 0.0046 - val_accuracy: 0.9991 - val_precision: 0.9983 - val_recall: 1.0000\n",
      "Epoch 45/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0249 - accuracy: 0.9929 - precision: 0.9885 - recall: 0.9974 - val_loss: 0.0069 - val_accuracy: 0.9978 - val_precision: 0.9957 - val_recall: 1.0000\n",
      "Epoch 46/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0275 - accuracy: 0.9932 - precision: 0.9877 - recall: 0.9990 - val_loss: 0.0029 - val_accuracy: 0.9996 - val_precision: 0.9991 - val_recall: 1.0000\n",
      "Epoch 47/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0230 - accuracy: 0.9942 - precision: 0.9899 - recall: 0.9986 - val_loss: 0.0043 - val_accuracy: 0.9991 - val_precision: 0.9983 - val_recall: 1.0000\n",
      "Epoch 48/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0221 - accuracy: 0.9947 - precision: 0.9921 - recall: 0.9974 - val_loss: 0.0054 - val_accuracy: 0.9983 - val_precision: 0.9965 - val_recall: 1.0000\n",
      "Epoch 49/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0228 - accuracy: 0.9930 - precision: 0.9882 - recall: 0.9979 - val_loss: 0.0028 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 50/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.9952 - precision: 0.9924 - recall: 0.9981 - val_loss: 0.0020 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 51/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0219 - accuracy: 0.9937 - precision: 0.9890 - recall: 0.9984 - val_loss: 0.0032 - val_accuracy: 0.9996 - val_precision: 0.9991 - val_recall: 1.0000\n",
      "Epoch 52/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.9957 - precision: 0.9929 - recall: 0.9984 - val_loss: 0.0028 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 53/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9948 - precision: 0.9914 - recall: 0.9983 - val_loss: 0.0024 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 54/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.9950 - precision: 0.9909 - recall: 0.9991 - val_loss: 0.0028 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 55/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0146 - accuracy: 0.9961 - precision: 0.9941 - recall: 0.9981 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 56/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9948 - precision: 0.9919 - recall: 0.9977 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 57/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0153 - accuracy: 0.9967 - precision: 0.9962 - recall: 0.9972 - val_loss: 0.0011 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 58/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.9945 - precision: 0.9907 - recall: 0.9984 - val_loss: 0.0020 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 59/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0157 - accuracy: 0.9956 - precision: 0.9933 - recall: 0.9979 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 60/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0132 - accuracy: 0.9965 - precision: 0.9943 - recall: 0.9988 - val_loss: 0.0017 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 61/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0153 - accuracy: 0.9964 - precision: 0.9941 - recall: 0.9988 - val_loss: 0.0026 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 62/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0157 - accuracy: 0.9957 - precision: 0.9929 - recall: 0.9984 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 63/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0159 - accuracy: 0.9951 - precision: 0.9926 - recall: 0.9977 - val_loss: 0.0014 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 64/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0155 - accuracy: 0.9957 - precision: 0.9924 - recall: 0.9990 - val_loss: 0.0011 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 65/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0168 - accuracy: 0.9958 - precision: 0.9931 - recall: 0.9984 - val_loss: 8.5165e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 66/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0129 - accuracy: 0.9967 - precision: 0.9948 - recall: 0.9986 - val_loss: 9.7672e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 67/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0139 - accuracy: 0.9967 - precision: 0.9955 - recall: 0.9979 - val_loss: 9.4456e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 68/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0115 - accuracy: 0.9967 - precision: 0.9938 - recall: 0.9997 - val_loss: 0.0014 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 69/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0128 - accuracy: 0.9966 - precision: 0.9945 - recall: 0.9988 - val_loss: 7.9379e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 70/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0142 - accuracy: 0.9965 - precision: 0.9945 - recall: 0.9986 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 71/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0118 - accuracy: 0.9971 - precision: 0.9953 - recall: 0.9988 - val_loss: 8.0874e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 72/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0118 - accuracy: 0.9967 - precision: 0.9948 - recall: 0.9986 - val_loss: 7.2354e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0122 - accuracy: 0.9974 - precision: 0.9957 - recall: 0.9991 - val_loss: 7.9069e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 74/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0111 - accuracy: 0.9966 - precision: 0.9945 - recall: 0.9988 - val_loss: 5.1305e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 75/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0124 - accuracy: 0.9964 - precision: 0.9945 - recall: 0.9984 - val_loss: 8.4951e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 76/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9984 - precision: 0.9969 - recall: 0.9998 - val_loss: 8.8213e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 77/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9971 - precision: 0.9950 - recall: 0.9991 - val_loss: 4.3965e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 78/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0092 - accuracy: 0.9972 - precision: 0.9962 - recall: 0.9983 - val_loss: 0.0013 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 79/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0105 - accuracy: 0.9971 - precision: 0.9950 - recall: 0.9993 - val_loss: 4.1882e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 80/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.9972 - precision: 0.9953 - recall: 0.9991 - val_loss: 5.1081e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 81/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9983 - precision: 0.9971 - recall: 0.9995 - val_loss: 7.4409e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 82/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.9981 - precision: 0.9967 - recall: 0.9995 - val_loss: 9.3481e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 83/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0091 - accuracy: 0.9975 - precision: 0.9959 - recall: 0.9991 - val_loss: 4.7673e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 84/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9977 - precision: 0.9962 - recall: 0.9993 - val_loss: 5.9357e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 85/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.9974 - precision: 0.9959 - recall: 0.9990 - val_loss: 7.0692e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 86/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9986 - precision: 0.9974 - recall: 0.9998 - val_loss: 3.5892e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 87/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0111 - accuracy: 0.9969 - precision: 0.9962 - recall: 0.9976 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 88/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.9973 - precision: 0.9955 - recall: 0.9991 - val_loss: 3.8545e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 89/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9985 - precision: 0.9978 - recall: 0.9993 - val_loss: 9.2513e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 90/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.9977 - precision: 0.9965 - recall: 0.9988 - val_loss: 4.3310e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 91/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.9977 - precision: 0.9957 - recall: 0.9997 - val_loss: 2.9632e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 92/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.9984 - precision: 0.9972 - recall: 0.9997 - val_loss: 4.1773e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 93/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0098 - accuracy: 0.9977 - precision: 0.9959 - recall: 0.9995 - val_loss: 2.4672e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 94/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9977 - precision: 0.9959 - recall: 0.9997 - val_loss: 2.7861e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 95/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9984 - precision: 0.9974 - recall: 0.9995 - val_loss: 4.0856e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 96/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9983 - precision: 0.9977 - recall: 0.9988 - val_loss: 3.4557e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 97/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9984 - precision: 0.9974 - recall: 0.9995 - val_loss: 1.9234e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 98/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9984 - precision: 0.9969 - recall: 0.9998 - val_loss: 2.8598e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 99/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9981 - precision: 0.9969 - recall: 0.9993 - val_loss: 2.4717e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 100/100\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9988 - precision: 0.9983 - recall: 0.9993 - val_loss: 1.5279e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Test accuracy: 1.0,Test Precision: 1.0,Test Recall: 1.0 ,Test loss: 0.0001527948770672083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Calculate class weights which could be used in the training of the model\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# # Pass the class weights to the fit method\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=100,\n",
    "#     batch_size=32,\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     class_weight=class_weights_dict,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# Pass the class weights to the fit method\n",
    "history = model.fit(\n",
    "    X_resampled,\n",
    "    y_resampled,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    class_weight=class_weights_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy},Test Precision: {test_precision},Test Recall: {test_recall} ,Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5a0f4e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 931us/step\n",
      "AUC-ROC: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_scores = model.predict(X_test)  # Get the predicted probabilities\n",
    "\n",
    "auc_roc = roc_auc_score(y_test, y_scores)\n",
    "\n",
    "print(f\"AUC-ROC: {auc_roc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0154acb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# To create a confusion matrix, you need to have actual predictions, not probabilities.\n",
    "# Let's say you decide on a threshold (you can adjust this as needed)\n",
    "threshold = 0.5\n",
    "y_pred = (y_scores >= threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
